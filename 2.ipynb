{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe5f417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1454205acd624df191d758dd56443fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b63aa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872824085a2443ba9da9ac3e6901f01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "dataset = load_dataset(\"yainage90/fashion-pattern-images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a7a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['argyle', 'camouflage', 'checked', 'dot', 'floral', 'geometric', 'gradient', 'graphic', 'houndstooth', 'leopard', 'lettering', 'muji', 'paisley', 'snake_skin', 'snow_flake', 'stripe', 'tropical', 'zebra', 'zigzag']\n"
     ]
    }
   ],
   "source": [
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "577185f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset size: 1520\n",
      "Testset size: 380\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the train set into train and test\n",
    "split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "trainset = split[\"train\"]\n",
    "testset = split[\"test\"]\n",
    "print(\"Trainset size:\", len(trainset))\n",
    "print(\"Testset size:\", len(testset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a84eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa82df6eb4f4586aa663634bf97c41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b43daa8bf6455591077cf750e755ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9513, 'grad_norm': 1.5533137321472168, 'learning_rate': 2.974736842105263e-05, 'epoch': 0.08}\n",
      "{'loss': 2.9309, 'grad_norm': 1.49404776096344, 'learning_rate': 2.9494736842105264e-05, 'epoch': 0.17}\n",
      "{'loss': 2.9204, 'grad_norm': 1.6879453659057617, 'learning_rate': 2.9242105263157893e-05, 'epoch': 0.25}\n",
      "{'loss': 2.8858, 'grad_norm': 1.7725534439086914, 'learning_rate': 2.8989473684210528e-05, 'epoch': 0.34}\n",
      "{'loss': 2.8753, 'grad_norm': 1.8019193410873413, 'learning_rate': 2.8736842105263157e-05, 'epoch': 0.42}\n",
      "{'loss': 2.8683, 'grad_norm': 1.9326295852661133, 'learning_rate': 2.8484210526315792e-05, 'epoch': 0.51}\n",
      "{'loss': 2.8435, 'grad_norm': 2.039621114730835, 'learning_rate': 2.823157894736842e-05, 'epoch': 0.59}\n",
      "{'loss': 2.8398, 'grad_norm': 1.8846739530563354, 'learning_rate': 2.7978947368421052e-05, 'epoch': 0.67}\n",
      "{'loss': 2.8038, 'grad_norm': 2.131182909011841, 'learning_rate': 2.7726315789473684e-05, 'epoch': 0.76}\n",
      "{'loss': 2.779, 'grad_norm': 1.9602160453796387, 'learning_rate': 2.7473684210526316e-05, 'epoch': 0.84}\n",
      "{'loss': 2.732, 'grad_norm': 2.111565113067627, 'learning_rate': 2.7221052631578948e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e4ccd434d9405b9ea512ebf4b56b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.708326578140259, 'eval_accuracy': 0.3894736842105263, 'eval_f1': 0.37057082658622426, 'eval_runtime': 52.3008, 'eval_samples_per_second': 7.266, 'eval_steps_per_second': 0.459, 'epoch': 1.0}\n",
      "{'loss': 2.6994, 'grad_norm': 1.9618207216262817, 'learning_rate': 2.696842105263158e-05, 'epoch': 1.01}\n",
      "{'loss': 2.5667, 'grad_norm': 2.3437774181365967, 'learning_rate': 2.671578947368421e-05, 'epoch': 1.09}\n",
      "{'loss': 2.5271, 'grad_norm': 2.0768721103668213, 'learning_rate': 2.6463157894736843e-05, 'epoch': 1.18}\n",
      "{'loss': 2.5167, 'grad_norm': 1.9647642374038696, 'learning_rate': 2.6210526315789475e-05, 'epoch': 1.26}\n",
      "{'loss': 2.4607, 'grad_norm': 1.9937245845794678, 'learning_rate': 2.5957894736842107e-05, 'epoch': 1.35}\n",
      "{'loss': 2.417, 'grad_norm': 2.1634106636047363, 'learning_rate': 2.5705263157894736e-05, 'epoch': 1.43}\n",
      "{'loss': 2.3732, 'grad_norm': 2.4954466819763184, 'learning_rate': 2.545263157894737e-05, 'epoch': 1.52}\n",
      "{'loss': 2.3961, 'grad_norm': 2.122347593307495, 'learning_rate': 2.52e-05, 'epoch': 1.6}\n",
      "{'loss': 2.2866, 'grad_norm': 2.2555344104766846, 'learning_rate': 2.4947368421052635e-05, 'epoch': 1.68}\n",
      "{'loss': 2.2304, 'grad_norm': 2.3657515048980713, 'learning_rate': 2.4694736842105263e-05, 'epoch': 1.77}\n",
      "{'loss': 2.2573, 'grad_norm': 2.2312405109405518, 'learning_rate': 2.4442105263157898e-05, 'epoch': 1.85}\n",
      "{'loss': 2.2241, 'grad_norm': 2.2694625854492188, 'learning_rate': 2.4189473684210527e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc1c2cfd704482ebcdc1aae2ff9102d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.248154878616333, 'eval_accuracy': 0.6394736842105263, 'eval_f1': 0.6200860764481894, 'eval_runtime': 52.0088, 'eval_samples_per_second': 7.306, 'eval_steps_per_second': 0.461, 'epoch': 2.0}\n",
      "{'loss': 2.1575, 'grad_norm': 2.396374464035034, 'learning_rate': 2.393684210526316e-05, 'epoch': 2.02}\n",
      "{'loss': 1.9761, 'grad_norm': 2.0862865447998047, 'learning_rate': 2.368421052631579e-05, 'epoch': 2.11}\n",
      "{'loss': 1.9847, 'grad_norm': 2.7507364749908447, 'learning_rate': 2.343157894736842e-05, 'epoch': 2.19}\n",
      "{'loss': 1.9455, 'grad_norm': 2.1163206100463867, 'learning_rate': 2.3178947368421054e-05, 'epoch': 2.27}\n",
      "{'loss': 1.8624, 'grad_norm': 2.4434568881988525, 'learning_rate': 2.2926315789473683e-05, 'epoch': 2.36}\n",
      "{'loss': 1.885, 'grad_norm': 1.9848313331604004, 'learning_rate': 2.2673684210526318e-05, 'epoch': 2.44}\n",
      "{'loss': 1.8012, 'grad_norm': 2.1632370948791504, 'learning_rate': 2.2421052631578946e-05, 'epoch': 2.53}\n",
      "{'loss': 1.7402, 'grad_norm': 2.1759791374206543, 'learning_rate': 2.216842105263158e-05, 'epoch': 2.61}\n",
      "{'loss': 1.8481, 'grad_norm': 2.552043914794922, 'learning_rate': 2.191578947368421e-05, 'epoch': 2.69}\n",
      "{'loss': 1.7061, 'grad_norm': 2.4763646125793457, 'learning_rate': 2.1663157894736842e-05, 'epoch': 2.78}\n",
      "{'loss': 1.6802, 'grad_norm': 2.39241099357605, 'learning_rate': 2.1410526315789474e-05, 'epoch': 2.86}\n",
      "{'loss': 1.7777, 'grad_norm': 2.9702131748199463, 'learning_rate': 2.1157894736842106e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e678dc5c1c204560b510c37b3f855ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8865337371826172, 'eval_accuracy': 0.6631578947368421, 'eval_f1': 0.6408467194550057, 'eval_runtime': 52.3625, 'eval_samples_per_second': 7.257, 'eval_steps_per_second': 0.458, 'epoch': 3.0}\n",
      "{'loss': 1.5966, 'grad_norm': 2.411165475845337, 'learning_rate': 2.0905263157894737e-05, 'epoch': 3.03}\n",
      "{'loss': 1.5441, 'grad_norm': 1.8495014905929565, 'learning_rate': 2.065263157894737e-05, 'epoch': 3.12}\n",
      "{'loss': 1.4552, 'grad_norm': 2.216501235961914, 'learning_rate': 2.04e-05, 'epoch': 3.2}\n",
      "{'loss': 1.4368, 'grad_norm': 2.518754005432129, 'learning_rate': 2.0147368421052633e-05, 'epoch': 3.28}\n",
      "{'loss': 1.4769, 'grad_norm': 2.180781126022339, 'learning_rate': 1.989473684210526e-05, 'epoch': 3.37}\n",
      "{'loss': 1.4411, 'grad_norm': 2.9849891662597656, 'learning_rate': 1.9642105263157897e-05, 'epoch': 3.45}\n",
      "{'loss': 1.422, 'grad_norm': 2.5317962169647217, 'learning_rate': 1.9389473684210525e-05, 'epoch': 3.54}\n",
      "{'loss': 1.3629, 'grad_norm': 3.8504090309143066, 'learning_rate': 1.913684210526316e-05, 'epoch': 3.62}\n",
      "{'loss': 1.3427, 'grad_norm': 2.5506296157836914, 'learning_rate': 1.888421052631579e-05, 'epoch': 3.71}\n",
      "{'loss': 1.282, 'grad_norm': 2.5831868648529053, 'learning_rate': 1.8631578947368424e-05, 'epoch': 3.79}\n",
      "{'loss': 1.2899, 'grad_norm': 2.2591421604156494, 'learning_rate': 1.8378947368421053e-05, 'epoch': 3.87}\n",
      "{'loss': 1.2948, 'grad_norm': 2.37800669670105, 'learning_rate': 1.8126315789473685e-05, 'epoch': 3.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a23b26a4d1f4df09762563041e76fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6447702646255493, 'eval_accuracy': 0.6947368421052632, 'eval_f1': 0.6901231020595284, 'eval_runtime': 52.5858, 'eval_samples_per_second': 7.226, 'eval_steps_per_second': 0.456, 'epoch': 4.0}\n",
      "{'loss': 1.2586, 'grad_norm': 2.147754430770874, 'learning_rate': 1.7873684210526316e-05, 'epoch': 4.04}\n",
      "{'loss': 1.1348, 'grad_norm': 1.8664156198501587, 'learning_rate': 1.7621052631578948e-05, 'epoch': 4.13}\n",
      "{'loss': 1.1296, 'grad_norm': 1.7795203924179077, 'learning_rate': 1.736842105263158e-05, 'epoch': 4.21}\n",
      "{'loss': 1.0826, 'grad_norm': 1.922107458114624, 'learning_rate': 1.711578947368421e-05, 'epoch': 4.29}\n",
      "{'loss': 1.0893, 'grad_norm': 1.8976538181304932, 'learning_rate': 1.6863157894736844e-05, 'epoch': 4.38}\n",
      "{'loss': 1.0906, 'grad_norm': 1.8544960021972656, 'learning_rate': 1.6610526315789472e-05, 'epoch': 4.46}\n",
      "{'loss': 1.0417, 'grad_norm': 2.1478354930877686, 'learning_rate': 1.6357894736842108e-05, 'epoch': 4.55}\n",
      "{'loss': 1.0268, 'grad_norm': 2.131279230117798, 'learning_rate': 1.6105263157894736e-05, 'epoch': 4.63}\n",
      "{'loss': 1.0091, 'grad_norm': 2.7032222747802734, 'learning_rate': 1.5852631578947368e-05, 'epoch': 4.72}\n",
      "{'loss': 1.036, 'grad_norm': 3.0610461235046387, 'learning_rate': 1.56e-05, 'epoch': 4.8}\n",
      "{'loss': 1.0231, 'grad_norm': 2.187838077545166, 'learning_rate': 1.534736842105263e-05, 'epoch': 4.88}\n",
      "{'loss': 1.0519, 'grad_norm': 2.311760425567627, 'learning_rate': 1.5094736842105265e-05, 'epoch': 4.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdabb1a1051245f8b904949bf0ad408f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4546823501586914, 'eval_accuracy': 0.7473684210526316, 'eval_f1': 0.7421800978216624, 'eval_runtime': 52.4351, 'eval_samples_per_second': 7.247, 'eval_steps_per_second': 0.458, 'epoch': 5.0}\n",
      "{'loss': 0.896, 'grad_norm': 1.6596311330795288, 'learning_rate': 1.4842105263157895e-05, 'epoch': 5.05}\n",
      "{'loss': 0.8942, 'grad_norm': 1.5796433687210083, 'learning_rate': 1.4589473684210527e-05, 'epoch': 5.14}\n",
      "{'loss': 0.8487, 'grad_norm': 1.4793360233306885, 'learning_rate': 1.4336842105263159e-05, 'epoch': 5.22}\n",
      "{'loss': 0.8793, 'grad_norm': 1.932173728942871, 'learning_rate': 1.408421052631579e-05, 'epoch': 5.31}\n",
      "{'loss': 0.8288, 'grad_norm': 1.4632599353790283, 'learning_rate': 1.3831578947368421e-05, 'epoch': 5.39}\n",
      "{'loss': 0.8661, 'grad_norm': 2.4419636726379395, 'learning_rate': 1.3578947368421053e-05, 'epoch': 5.47}\n",
      "{'loss': 0.8296, 'grad_norm': 2.045839548110962, 'learning_rate': 1.3326315789473685e-05, 'epoch': 5.56}\n",
      "{'loss': 0.8183, 'grad_norm': 2.830130100250244, 'learning_rate': 1.3073684210526315e-05, 'epoch': 5.64}\n",
      "{'loss': 0.7936, 'grad_norm': 1.461692452430725, 'learning_rate': 1.2821052631578947e-05, 'epoch': 5.73}\n",
      "{'loss': 0.8093, 'grad_norm': 1.648966908454895, 'learning_rate': 1.2568421052631579e-05, 'epoch': 5.81}\n",
      "{'loss': 0.7881, 'grad_norm': 1.8055847883224487, 'learning_rate': 1.231578947368421e-05, 'epoch': 5.89}\n",
      "{'loss': 0.7562, 'grad_norm': 1.397277593612671, 'learning_rate': 1.2063157894736842e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a097c1f8cb9454c92672413133aa059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.334495186805725, 'eval_accuracy': 0.7421052631578947, 'eval_f1': 0.7380645096311316, 'eval_runtime': 50.6976, 'eval_samples_per_second': 7.495, 'eval_steps_per_second': 0.473, 'epoch': 6.0}\n",
      "{'loss': 0.735, 'grad_norm': 2.524820327758789, 'learning_rate': 1.1810526315789474e-05, 'epoch': 6.06}\n",
      "{'loss': 0.6792, 'grad_norm': 1.831991195678711, 'learning_rate': 1.1557894736842106e-05, 'epoch': 6.15}\n",
      "{'loss': 0.7017, 'grad_norm': 1.5670113563537598, 'learning_rate': 1.1305263157894736e-05, 'epoch': 6.23}\n",
      "{'loss': 0.6789, 'grad_norm': 1.7557810544967651, 'learning_rate': 1.1052631578947368e-05, 'epoch': 6.32}\n",
      "{'loss': 0.6574, 'grad_norm': 1.3228693008422852, 'learning_rate': 1.08e-05, 'epoch': 6.4}\n",
      "{'loss': 0.6253, 'grad_norm': 1.4633392095565796, 'learning_rate': 1.0547368421052632e-05, 'epoch': 6.48}\n",
      "{'loss': 0.6013, 'grad_norm': 1.3782529830932617, 'learning_rate': 1.0294736842105264e-05, 'epoch': 6.57}\n",
      "{'loss': 0.6644, 'grad_norm': 2.1547977924346924, 'learning_rate': 1.0042105263157896e-05, 'epoch': 6.65}\n",
      "{'loss': 0.6315, 'grad_norm': 1.5058737993240356, 'learning_rate': 9.789473684210527e-06, 'epoch': 6.74}\n",
      "{'loss': 0.6464, 'grad_norm': 1.328420877456665, 'learning_rate': 9.53684210526316e-06, 'epoch': 6.82}\n",
      "{'loss': 0.6201, 'grad_norm': 1.4061967134475708, 'learning_rate': 9.28421052631579e-06, 'epoch': 6.91}\n",
      "{'loss': 0.6203, 'grad_norm': 1.8237476348876953, 'learning_rate': 9.031578947368421e-06, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d94dd800a049978c6b7f49d4e8d36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2774536609649658, 'eval_accuracy': 0.7289473684210527, 'eval_f1': 0.7283410560298298, 'eval_runtime': 51.9295, 'eval_samples_per_second': 7.318, 'eval_steps_per_second': 0.462, 'epoch': 7.0}\n",
      "{'loss': 0.5936, 'grad_norm': 1.6169304847717285, 'learning_rate': 8.778947368421053e-06, 'epoch': 7.07}\n",
      "{'loss': 0.5942, 'grad_norm': 1.5342814922332764, 'learning_rate': 8.526315789473685e-06, 'epoch': 7.16}\n",
      "{'loss': 0.581, 'grad_norm': 1.2384439706802368, 'learning_rate': 8.273684210526317e-06, 'epoch': 7.24}\n",
      "{'loss': 0.5367, 'grad_norm': 1.3140690326690674, 'learning_rate': 8.021052631578949e-06, 'epoch': 7.33}\n",
      "{'loss': 0.5107, 'grad_norm': 1.3429896831512451, 'learning_rate': 7.768421052631579e-06, 'epoch': 7.41}\n",
      "{'loss': 0.5428, 'grad_norm': 1.4011050462722778, 'learning_rate': 7.5157894736842115e-06, 'epoch': 7.49}\n",
      "{'loss': 0.5386, 'grad_norm': 1.5545356273651123, 'learning_rate': 7.2631578947368426e-06, 'epoch': 7.58}\n",
      "{'loss': 0.5149, 'grad_norm': 1.0314152240753174, 'learning_rate': 7.010526315789474e-06, 'epoch': 7.66}\n",
      "{'loss': 0.533, 'grad_norm': 2.2956204414367676, 'learning_rate': 6.7578947368421054e-06, 'epoch': 7.75}\n",
      "{'loss': 0.5157, 'grad_norm': 1.4218480587005615, 'learning_rate': 6.505263157894737e-06, 'epoch': 7.83}\n",
      "{'loss': 0.5189, 'grad_norm': 1.2222236394882202, 'learning_rate': 6.252631578947368e-06, 'epoch': 7.92}\n",
      "{'loss': 0.5137, 'grad_norm': 1.2129379510879517, 'learning_rate': 6e-06, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d5c3913c174ef196eed262299297c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2159501314163208, 'eval_accuracy': 0.7368421052631579, 'eval_f1': 0.7344828353753896, 'eval_runtime': 50.4995, 'eval_samples_per_second': 7.525, 'eval_steps_per_second': 0.475, 'epoch': 8.0}\n",
      "{'loss': 0.4717, 'grad_norm': 1.0261173248291016, 'learning_rate': 5.747368421052631e-06, 'epoch': 8.08}\n",
      "{'loss': 0.4718, 'grad_norm': 0.9143159985542297, 'learning_rate': 5.494736842105263e-06, 'epoch': 8.17}\n",
      "{'loss': 0.4926, 'grad_norm': 0.991754949092865, 'learning_rate': 5.242105263157895e-06, 'epoch': 8.25}\n",
      "{'loss': 0.4705, 'grad_norm': 1.063393235206604, 'learning_rate': 4.989473684210527e-06, 'epoch': 8.34}\n",
      "{'loss': 0.4888, 'grad_norm': 1.427108645439148, 'learning_rate': 4.736842105263158e-06, 'epoch': 8.42}\n",
      "{'loss': 0.4695, 'grad_norm': 1.043702483177185, 'learning_rate': 4.48421052631579e-06, 'epoch': 8.51}\n",
      "{'loss': 0.4945, 'grad_norm': 1.177340030670166, 'learning_rate': 4.2315789473684215e-06, 'epoch': 8.59}\n",
      "{'loss': 0.4644, 'grad_norm': 1.1340672969818115, 'learning_rate': 3.978947368421053e-06, 'epoch': 8.67}\n",
      "{'loss': 0.4549, 'grad_norm': 0.9387328028678894, 'learning_rate': 3.7263157894736843e-06, 'epoch': 8.76}\n",
      "{'loss': 0.4539, 'grad_norm': 1.1040308475494385, 'learning_rate': 3.4736842105263158e-06, 'epoch': 8.84}\n",
      "{'loss': 0.463, 'grad_norm': 1.3408784866333008, 'learning_rate': 3.2210526315789476e-06, 'epoch': 8.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6a324332034c66911da42cbc3d4232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1916773319244385, 'eval_accuracy': 0.7315789473684211, 'eval_f1': 0.730497875346291, 'eval_runtime': 53.1814, 'eval_samples_per_second': 7.145, 'eval_steps_per_second': 0.451, 'epoch': 9.0}\n",
      "{'loss': 0.4589, 'grad_norm': 1.1218756437301636, 'learning_rate': 2.968421052631579e-06, 'epoch': 9.01}\n",
      "{'loss': 0.4378, 'grad_norm': 1.079724907875061, 'learning_rate': 2.715789473684211e-06, 'epoch': 9.09}\n",
      "{'loss': 0.4468, 'grad_norm': 1.0606586933135986, 'learning_rate': 2.4631578947368424e-06, 'epoch': 9.18}\n",
      "{'loss': 0.422, 'grad_norm': 0.9863461256027222, 'learning_rate': 2.2105263157894734e-06, 'epoch': 9.26}\n",
      "{'loss': 0.435, 'grad_norm': 0.9780309796333313, 'learning_rate': 1.9578947368421052e-06, 'epoch': 9.35}\n",
      "{'loss': 0.4376, 'grad_norm': 0.9087545871734619, 'learning_rate': 1.7052631578947369e-06, 'epoch': 9.43}\n",
      "{'loss': 0.437, 'grad_norm': 0.8572819232940674, 'learning_rate': 1.4526315789473685e-06, 'epoch': 9.52}\n",
      "{'loss': 0.442, 'grad_norm': 1.090192198753357, 'learning_rate': 1.2000000000000002e-06, 'epoch': 9.6}\n",
      "{'loss': 0.4329, 'grad_norm': 0.984957218170166, 'learning_rate': 9.473684210526316e-07, 'epoch': 9.68}\n",
      "{'loss': 0.4394, 'grad_norm': 0.8629277348518372, 'learning_rate': 6.947368421052632e-07, 'epoch': 9.77}\n",
      "{'loss': 0.4379, 'grad_norm': 1.1021788120269775, 'learning_rate': 4.421052631578947e-07, 'epoch': 9.85}\n",
      "{'loss': 0.4499, 'grad_norm': 0.9678919911384583, 'learning_rate': 1.8947368421052632e-07, 'epoch': 9.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40febdcde5144897952357a081f09269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1873637437820435, 'eval_accuracy': 0.7342105263157894, 'eval_f1': 0.7323141919249194, 'eval_runtime': 51.102, 'eval_samples_per_second': 7.436, 'eval_steps_per_second': 0.47, 'epoch': 10.0}\n",
      "{'train_runtime': 5227.7836, 'train_samples_per_second': 2.908, 'train_steps_per_second': 0.182, 'train_loss': 1.2449252640573603, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fe2e4573ab463e9d088e4a943f85cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1873637437820435, 'eval_accuracy': 0.7342105263157894, 'eval_f1': 0.7323141919249194, 'eval_runtime': 51.7452, 'eval_samples_per_second': 7.344, 'eval_steps_per_second': 0.464, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load dataset and split\n",
    "dataset = load_dataset(\"yainage90/fashion-pattern-images\")\n",
    "split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "trainset = split[\"train\"]\n",
    "testset = split[\"test\"]\n",
    "\n",
    "# Get label info\n",
    "labels = trainset.features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "id2label = {str(i): l for i, l in enumerate(labels)}\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "\n",
    "# Preprocessing (ViT processor + optional augmentation)\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def transform_examples(batch):\n",
    "    # Data augmentation only on training set\n",
    "    if \"train\" in batch[\"__split__\"][0]:\n",
    "        images = [augment(img.convert(\"RGB\")) for img in batch[\"image\"]]\n",
    "    else:\n",
    "        images = [img.convert(\"RGB\") for img in batch[\"image\"]]\n",
    "    processed = processor(images=images, return_tensors=\"pt\")\n",
    "    # Remove batch dimension for each image\n",
    "    pixel_values = [img for img in processed[\"pixel_values\"]]\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"labels\": batch[\"label\"]\n",
    "    }\n",
    "\n",
    "# Add split info for augmentation\n",
    "trainset = trainset.add_column(\"__split__\", [\"train\"] * len(trainset))\n",
    "testset = testset.add_column(\"__split__\", [\"test\"] * len(testset))\n",
    "\n",
    "trainset = trainset.map(transform_examples, batched=True, remove_columns=trainset.column_names)\n",
    "testset = testset.map(transform_examples, batched=True, remove_columns=testset.column_names)\n",
    "\n",
    "# Model\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "    labels = torch.tensor([x[\"labels\"] for x in batch])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit-pattern\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,  # Try more epochs for better results\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=8,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=True,\n",
    "    report_to=\"none\",\n",
    "    learning_rate=3e-5,  # Lower learning rate for better fine-tuning\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset,\n",
    "    eval_dataset=testset,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=None,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99271a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a55735e4b0a4af0a7863ce0a4978842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e664b91ffca641268cdf36fe5cc5b962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9334, 'grad_norm': 1.889012098312378, 'learning_rate': 2.974736842105263e-05, 'epoch': 0.08}\n",
      "{'loss': 2.9303, 'grad_norm': 1.8285527229309082, 'learning_rate': 2.9494736842105264e-05, 'epoch': 0.17}\n",
      "{'loss': 2.8979, 'grad_norm': 1.72324538230896, 'learning_rate': 2.9242105263157893e-05, 'epoch': 0.25}\n",
      "{'loss': 2.8921, 'grad_norm': 1.7049087285995483, 'learning_rate': 2.8989473684210528e-05, 'epoch': 0.34}\n",
      "{'loss': 2.8601, 'grad_norm': 1.9082345962524414, 'learning_rate': 2.8736842105263157e-05, 'epoch': 0.42}\n",
      "{'loss': 2.8629, 'grad_norm': 1.9359761476516724, 'learning_rate': 2.8484210526315792e-05, 'epoch': 0.51}\n",
      "{'loss': 2.8435, 'grad_norm': 2.0235798358917236, 'learning_rate': 2.823157894736842e-05, 'epoch': 0.59}\n",
      "{'loss': 2.8228, 'grad_norm': 2.0750834941864014, 'learning_rate': 2.7978947368421052e-05, 'epoch': 0.67}\n",
      "{'loss': 2.7832, 'grad_norm': 2.2923481464385986, 'learning_rate': 2.7726315789473684e-05, 'epoch': 0.76}\n",
      "{'loss': 2.7549, 'grad_norm': 2.029365062713623, 'learning_rate': 2.7473684210526316e-05, 'epoch': 0.84}\n",
      "{'loss': 2.6734, 'grad_norm': 2.1360630989074707, 'learning_rate': 2.7221052631578948e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9ee8e9088c41a5b1e41d634d0fb653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6859734058380127, 'eval_accuracy': 0.41842105263157897, 'eval_f1': 0.3808719190907127, 'eval_runtime': 113.0618, 'eval_samples_per_second': 3.361, 'eval_steps_per_second': 0.212, 'epoch': 1.0}\n",
      "{'loss': 2.6624, 'grad_norm': 1.9285041093826294, 'learning_rate': 2.696842105263158e-05, 'epoch': 1.01}\n",
      "{'loss': 2.5331, 'grad_norm': 2.1956522464752197, 'learning_rate': 2.671578947368421e-05, 'epoch': 1.09}\n",
      "{'loss': 2.4866, 'grad_norm': 2.08432936668396, 'learning_rate': 2.6463157894736843e-05, 'epoch': 1.18}\n",
      "{'loss': 2.4587, 'grad_norm': 1.9122259616851807, 'learning_rate': 2.6210526315789475e-05, 'epoch': 1.26}\n",
      "{'loss': 2.4089, 'grad_norm': 1.9667901992797852, 'learning_rate': 2.5957894736842107e-05, 'epoch': 1.35}\n",
      "{'loss': 2.3896, 'grad_norm': 2.1207916736602783, 'learning_rate': 2.5705263157894736e-05, 'epoch': 1.43}\n",
      "{'loss': 2.3408, 'grad_norm': 2.1696579456329346, 'learning_rate': 2.545263157894737e-05, 'epoch': 1.52}\n",
      "{'loss': 2.3313, 'grad_norm': 2.1553730964660645, 'learning_rate': 2.52e-05, 'epoch': 1.6}\n",
      "{'loss': 2.2684, 'grad_norm': 2.877537250518799, 'learning_rate': 2.4947368421052635e-05, 'epoch': 1.68}\n",
      "{'loss': 2.1861, 'grad_norm': 2.2490923404693604, 'learning_rate': 2.4694736842105263e-05, 'epoch': 1.77}\n",
      "{'loss': 2.2171, 'grad_norm': 2.252920150756836, 'learning_rate': 2.4442105263157898e-05, 'epoch': 1.85}\n",
      "{'loss': 2.2141, 'grad_norm': 2.209381103515625, 'learning_rate': 2.4189473684210527e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51d419dea584781b47dd20dce1e38a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2480416297912598, 'eval_accuracy': 0.6263157894736842, 'eval_f1': 0.6019023120179844, 'eval_runtime': 95.3121, 'eval_samples_per_second': 3.987, 'eval_steps_per_second': 0.252, 'epoch': 2.0}\n",
      "{'loss': 2.1261, 'grad_norm': 2.538963556289673, 'learning_rate': 2.393684210526316e-05, 'epoch': 2.02}\n",
      "{'loss': 1.9694, 'grad_norm': 2.384615898132324, 'learning_rate': 2.368421052631579e-05, 'epoch': 2.11}\n",
      "{'loss': 1.9442, 'grad_norm': 2.289508581161499, 'learning_rate': 2.343157894736842e-05, 'epoch': 2.19}\n",
      "{'loss': 1.9172, 'grad_norm': 2.1681413650512695, 'learning_rate': 2.3178947368421054e-05, 'epoch': 2.27}\n",
      "{'loss': 1.877, 'grad_norm': 2.1226418018341064, 'learning_rate': 2.2926315789473683e-05, 'epoch': 2.36}\n",
      "{'loss': 1.85, 'grad_norm': 1.9248988628387451, 'learning_rate': 2.2673684210526318e-05, 'epoch': 2.44}\n",
      "{'loss': 1.8261, 'grad_norm': 2.5146727561950684, 'learning_rate': 2.2421052631578946e-05, 'epoch': 2.53}\n",
      "{'loss': 1.7334, 'grad_norm': 2.9920055866241455, 'learning_rate': 2.216842105263158e-05, 'epoch': 2.61}\n",
      "{'loss': 1.7673, 'grad_norm': 2.3052480220794678, 'learning_rate': 2.191578947368421e-05, 'epoch': 2.69}\n",
      "{'loss': 1.6877, 'grad_norm': 2.2063510417938232, 'learning_rate': 2.1663157894736842e-05, 'epoch': 2.78}\n",
      "{'loss': 1.6232, 'grad_norm': 2.527080774307251, 'learning_rate': 2.1410526315789474e-05, 'epoch': 2.86}\n",
      "{'loss': 1.7808, 'grad_norm': 4.397936820983887, 'learning_rate': 2.1157894736842106e-05, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be21fd1a15b64ebf997d31882b8f3104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.88667893409729, 'eval_accuracy': 0.6736842105263158, 'eval_f1': 0.6571778469512564, 'eval_runtime': 74.4352, 'eval_samples_per_second': 5.105, 'eval_steps_per_second': 0.322, 'epoch': 3.0}\n",
      "{'loss': 1.5581, 'grad_norm': 2.4517459869384766, 'learning_rate': 2.0905263157894737e-05, 'epoch': 3.03}\n",
      "{'loss': 1.5248, 'grad_norm': 1.8101624250411987, 'learning_rate': 2.065263157894737e-05, 'epoch': 3.12}\n",
      "{'loss': 1.4207, 'grad_norm': 2.083425283432007, 'learning_rate': 2.04e-05, 'epoch': 3.2}\n",
      "{'loss': 1.41, 'grad_norm': 2.358433961868286, 'learning_rate': 2.0147368421052633e-05, 'epoch': 3.28}\n",
      "{'loss': 1.4652, 'grad_norm': 2.7642390727996826, 'learning_rate': 1.989473684210526e-05, 'epoch': 3.37}\n",
      "{'loss': 1.419, 'grad_norm': 2.5002408027648926, 'learning_rate': 1.9642105263157897e-05, 'epoch': 3.45}\n",
      "{'loss': 1.4183, 'grad_norm': 2.3595733642578125, 'learning_rate': 1.9389473684210525e-05, 'epoch': 3.54}\n",
      "{'loss': 1.3761, 'grad_norm': 2.137265682220459, 'learning_rate': 1.913684210526316e-05, 'epoch': 3.62}\n",
      "{'loss': 1.3047, 'grad_norm': 2.3391973972320557, 'learning_rate': 1.888421052631579e-05, 'epoch': 3.71}\n",
      "{'loss': 1.2835, 'grad_norm': 2.6572561264038086, 'learning_rate': 1.8631578947368424e-05, 'epoch': 3.79}\n",
      "{'loss': 1.2946, 'grad_norm': 2.509253978729248, 'learning_rate': 1.8378947368421053e-05, 'epoch': 3.87}\n",
      "{'loss': 1.2688, 'grad_norm': 3.3374135494232178, 'learning_rate': 1.8126315789473685e-05, 'epoch': 3.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498d725882e94c02972d488c0d8036a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.63411545753479, 'eval_accuracy': 0.7236842105263158, 'eval_f1': 0.7143545182479067, 'eval_runtime': 128.3195, 'eval_samples_per_second': 2.961, 'eval_steps_per_second': 0.187, 'epoch': 4.0}\n",
      "{'loss': 1.2452, 'grad_norm': 2.3106367588043213, 'learning_rate': 1.7873684210526316e-05, 'epoch': 4.04}\n",
      "{'loss': 1.1457, 'grad_norm': 2.703010320663452, 'learning_rate': 1.7621052631578948e-05, 'epoch': 4.13}\n",
      "{'loss': 1.1294, 'grad_norm': 1.9474276304244995, 'learning_rate': 1.736842105263158e-05, 'epoch': 4.21}\n",
      "{'loss': 1.0698, 'grad_norm': 2.300886631011963, 'learning_rate': 1.711578947368421e-05, 'epoch': 4.29}\n",
      "{'loss': 1.0751, 'grad_norm': 2.1971287727355957, 'learning_rate': 1.6863157894736844e-05, 'epoch': 4.38}\n",
      "{'loss': 1.0903, 'grad_norm': 1.9363985061645508, 'learning_rate': 1.6610526315789472e-05, 'epoch': 4.46}\n",
      "{'loss': 1.0226, 'grad_norm': 2.4788880348205566, 'learning_rate': 1.6357894736842108e-05, 'epoch': 4.55}\n",
      "{'loss': 1.0394, 'grad_norm': 1.8380842208862305, 'learning_rate': 1.6105263157894736e-05, 'epoch': 4.63}\n",
      "{'loss': 0.9875, 'grad_norm': 3.8484158515930176, 'learning_rate': 1.5852631578947368e-05, 'epoch': 4.72}\n",
      "{'loss': 1.0503, 'grad_norm': 2.843790292739868, 'learning_rate': 1.56e-05, 'epoch': 4.8}\n",
      "{'loss': 1.005, 'grad_norm': 1.9371051788330078, 'learning_rate': 1.534736842105263e-05, 'epoch': 4.88}\n",
      "{'loss': 1.0344, 'grad_norm': 1.588873028755188, 'learning_rate': 1.5094736842105265e-05, 'epoch': 4.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902f1e41478648b4a6eb76b042d27c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4474661350250244, 'eval_accuracy': 0.7473684210526316, 'eval_f1': 0.7409928401993879, 'eval_runtime': 52.4727, 'eval_samples_per_second': 7.242, 'eval_steps_per_second': 0.457, 'epoch': 5.0}\n",
      "{'loss': 0.8983, 'grad_norm': 1.4935849905014038, 'learning_rate': 1.4842105263157895e-05, 'epoch': 5.05}\n",
      "{'loss': 0.8813, 'grad_norm': 1.7877466678619385, 'learning_rate': 1.4589473684210527e-05, 'epoch': 5.14}\n",
      "{'loss': 0.8462, 'grad_norm': 1.4427244663238525, 'learning_rate': 1.4336842105263159e-05, 'epoch': 5.22}\n",
      "{'loss': 0.8798, 'grad_norm': 2.305615186691284, 'learning_rate': 1.408421052631579e-05, 'epoch': 5.31}\n",
      "{'loss': 0.8319, 'grad_norm': 1.4197845458984375, 'learning_rate': 1.3831578947368421e-05, 'epoch': 5.39}\n",
      "{'loss': 0.8614, 'grad_norm': 2.501708507537842, 'learning_rate': 1.3578947368421053e-05, 'epoch': 5.47}\n",
      "{'loss': 0.8176, 'grad_norm': 1.7151557207107544, 'learning_rate': 1.3326315789473685e-05, 'epoch': 5.56}\n",
      "{'loss': 0.8057, 'grad_norm': 3.1731605529785156, 'learning_rate': 1.3073684210526315e-05, 'epoch': 5.64}\n",
      "{'loss': 0.7794, 'grad_norm': 1.8898909091949463, 'learning_rate': 1.2821052631578947e-05, 'epoch': 5.73}\n",
      "{'loss': 0.8126, 'grad_norm': 1.9623557329177856, 'learning_rate': 1.2568421052631579e-05, 'epoch': 5.81}\n",
      "{'loss': 0.7978, 'grad_norm': 2.116133451461792, 'learning_rate': 1.231578947368421e-05, 'epoch': 5.89}\n",
      "{'loss': 0.7574, 'grad_norm': 1.4964790344238281, 'learning_rate': 1.2063157894736842e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad0ed4d7ab04cfa828eec5d281c0edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.324196219444275, 'eval_accuracy': 0.7631578947368421, 'eval_f1': 0.7607690809536142, 'eval_runtime': 54.0464, 'eval_samples_per_second': 7.031, 'eval_steps_per_second': 0.444, 'epoch': 6.0}\n",
      "{'loss': 0.7114, 'grad_norm': 2.043274164199829, 'learning_rate': 1.1810526315789474e-05, 'epoch': 6.06}\n",
      "{'loss': 0.6761, 'grad_norm': 1.5924066305160522, 'learning_rate': 1.1557894736842106e-05, 'epoch': 6.15}\n",
      "{'loss': 0.6953, 'grad_norm': 1.6386523246765137, 'learning_rate': 1.1305263157894736e-05, 'epoch': 6.23}\n",
      "{'loss': 0.6932, 'grad_norm': 1.6725308895111084, 'learning_rate': 1.1052631578947368e-05, 'epoch': 6.32}\n",
      "{'loss': 0.6493, 'grad_norm': 1.3465479612350464, 'learning_rate': 1.08e-05, 'epoch': 6.4}\n",
      "{'loss': 0.6227, 'grad_norm': 1.279639482498169, 'learning_rate': 1.0547368421052632e-05, 'epoch': 6.48}\n",
      "{'loss': 0.5951, 'grad_norm': 1.407650351524353, 'learning_rate': 1.0294736842105264e-05, 'epoch': 6.57}\n",
      "{'loss': 0.6387, 'grad_norm': 1.9260202646255493, 'learning_rate': 1.0042105263157896e-05, 'epoch': 6.65}\n",
      "{'loss': 0.6162, 'grad_norm': 2.1322810649871826, 'learning_rate': 9.789473684210527e-06, 'epoch': 6.74}\n",
      "{'loss': 0.6638, 'grad_norm': 1.6485357284545898, 'learning_rate': 9.53684210526316e-06, 'epoch': 6.82}\n",
      "{'loss': 0.6397, 'grad_norm': 1.4212465286254883, 'learning_rate': 9.28421052631579e-06, 'epoch': 6.91}\n",
      "{'loss': 0.6147, 'grad_norm': 2.5384938716888428, 'learning_rate': 9.031578947368421e-06, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919b60fa7a694bf28ee22dce98619693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2436517477035522, 'eval_accuracy': 0.75, 'eval_f1': 0.7465532295634228, 'eval_runtime': 53.9218, 'eval_samples_per_second': 7.047, 'eval_steps_per_second': 0.445, 'epoch': 7.0}\n",
      "{'loss': 0.5816, 'grad_norm': 1.4623305797576904, 'learning_rate': 8.778947368421053e-06, 'epoch': 7.07}\n",
      "{'loss': 0.5936, 'grad_norm': 1.2557752132415771, 'learning_rate': 8.526315789473685e-06, 'epoch': 7.16}\n",
      "{'loss': 0.5669, 'grad_norm': 1.2263545989990234, 'learning_rate': 8.273684210526317e-06, 'epoch': 7.24}\n",
      "{'loss': 0.5163, 'grad_norm': 1.102920413017273, 'learning_rate': 8.021052631578949e-06, 'epoch': 7.33}\n",
      "{'loss': 0.5096, 'grad_norm': 1.2629755735397339, 'learning_rate': 7.768421052631579e-06, 'epoch': 7.41}\n",
      "{'loss': 0.5522, 'grad_norm': 1.1942319869995117, 'learning_rate': 7.5157894736842115e-06, 'epoch': 7.49}\n",
      "{'loss': 0.5362, 'grad_norm': 1.1898623704910278, 'learning_rate': 7.2631578947368426e-06, 'epoch': 7.58}\n",
      "{'loss': 0.5063, 'grad_norm': 1.2049922943115234, 'learning_rate': 7.010526315789474e-06, 'epoch': 7.66}\n",
      "{'loss': 0.5376, 'grad_norm': 2.0156307220458984, 'learning_rate': 6.7578947368421054e-06, 'epoch': 7.75}\n",
      "{'loss': 0.5103, 'grad_norm': 1.065365195274353, 'learning_rate': 6.505263157894737e-06, 'epoch': 7.83}\n",
      "{'loss': 0.5134, 'grad_norm': 1.1790963411331177, 'learning_rate': 6.252631578947368e-06, 'epoch': 7.92}\n",
      "{'loss': 0.4931, 'grad_norm': 2.0026490688323975, 'learning_rate': 6e-06, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4a19ba2f95414fb0d9a8b635551fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1957699060440063, 'eval_accuracy': 0.75, 'eval_f1': 0.7470298530111844, 'eval_runtime': 50.7758, 'eval_samples_per_second': 7.484, 'eval_steps_per_second': 0.473, 'epoch': 8.0}\n",
      "{'loss': 0.4649, 'grad_norm': 1.0138967037200928, 'learning_rate': 5.747368421052631e-06, 'epoch': 8.08}\n",
      "{'loss': 0.4693, 'grad_norm': 0.9548399448394775, 'learning_rate': 5.494736842105263e-06, 'epoch': 8.17}\n",
      "{'loss': 0.48, 'grad_norm': 1.041069746017456, 'learning_rate': 5.242105263157895e-06, 'epoch': 8.25}\n",
      "{'loss': 0.4761, 'grad_norm': 1.124782919883728, 'learning_rate': 4.989473684210527e-06, 'epoch': 8.34}\n",
      "{'loss': 0.474, 'grad_norm': 1.2339004278182983, 'learning_rate': 4.736842105263158e-06, 'epoch': 8.42}\n",
      "{'loss': 0.4603, 'grad_norm': 1.1868741512298584, 'learning_rate': 4.48421052631579e-06, 'epoch': 8.51}\n",
      "{'loss': 0.4909, 'grad_norm': 1.0428881645202637, 'learning_rate': 4.2315789473684215e-06, 'epoch': 8.59}\n",
      "{'loss': 0.4503, 'grad_norm': 1.744766354560852, 'learning_rate': 3.978947368421053e-06, 'epoch': 8.67}\n",
      "{'loss': 0.4398, 'grad_norm': 0.9476062655448914, 'learning_rate': 3.7263157894736843e-06, 'epoch': 8.76}\n",
      "{'loss': 0.4559, 'grad_norm': 0.9855421185493469, 'learning_rate': 3.4736842105263158e-06, 'epoch': 8.84}\n",
      "{'loss': 0.4526, 'grad_norm': 1.170641541481018, 'learning_rate': 3.2210526315789476e-06, 'epoch': 8.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a732714d0d4dd79babbe33a693752a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1650307178497314, 'eval_accuracy': 0.7526315789473684, 'eval_f1': 0.7506950046885792, 'eval_runtime': 51.7999, 'eval_samples_per_second': 7.336, 'eval_steps_per_second': 0.463, 'epoch': 9.0}\n",
      "{'loss': 0.4488, 'grad_norm': 0.986046552658081, 'learning_rate': 2.968421052631579e-06, 'epoch': 9.01}\n",
      "{'loss': 0.4256, 'grad_norm': 1.0235873460769653, 'learning_rate': 2.715789473684211e-06, 'epoch': 9.09}\n",
      "{'loss': 0.4639, 'grad_norm': 1.0451924800872803, 'learning_rate': 2.4631578947368424e-06, 'epoch': 9.18}\n",
      "{'loss': 0.4194, 'grad_norm': 0.969524085521698, 'learning_rate': 2.2105263157894734e-06, 'epoch': 9.26}\n",
      "{'loss': 0.4243, 'grad_norm': 0.9470532536506653, 'learning_rate': 1.9578947368421052e-06, 'epoch': 9.35}\n",
      "{'loss': 0.4226, 'grad_norm': 2.724477529525757, 'learning_rate': 1.7052631578947369e-06, 'epoch': 9.43}\n",
      "{'loss': 0.4193, 'grad_norm': 0.7828384041786194, 'learning_rate': 1.4526315789473685e-06, 'epoch': 9.52}\n",
      "{'loss': 0.4427, 'grad_norm': 1.0531713962554932, 'learning_rate': 1.2000000000000002e-06, 'epoch': 9.6}\n",
      "{'loss': 0.4227, 'grad_norm': 0.9883484840393066, 'learning_rate': 9.473684210526316e-07, 'epoch': 9.68}\n",
      "{'loss': 0.4324, 'grad_norm': 0.8468035459518433, 'learning_rate': 6.947368421052632e-07, 'epoch': 9.77}\n",
      "{'loss': 0.4292, 'grad_norm': 1.0944509506225586, 'learning_rate': 4.421052631578947e-07, 'epoch': 9.85}\n",
      "{'loss': 0.4308, 'grad_norm': 0.9274795055389404, 'learning_rate': 1.8947368421052632e-07, 'epoch': 9.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c8cbd0619e43558fe4d55278217aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.15370774269104, 'eval_accuracy': 0.75, 'eval_f1': 0.7489343388324992, 'eval_runtime': 57.2709, 'eval_samples_per_second': 6.635, 'eval_steps_per_second': 0.419, 'epoch': 10.0}\n",
      "{'train_runtime': 5108.05, 'train_samples_per_second': 2.976, 'train_steps_per_second': 0.186, 'train_loss': 1.2321367283871298, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445dd8ac17c0455697fc43778916fd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.15370774269104, 'eval_accuracy': 0.75, 'eval_f1': 0.7489343388324992, 'eval_runtime': 56.1626, 'eval_samples_per_second': 6.766, 'eval_steps_per_second': 0.427, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load dataset and split\n",
    "dataset = load_dataset(\"yainage90/fashion-pattern-images\")\n",
    "split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "trainset = split[\"train\"]\n",
    "testset = split[\"test\"]\n",
    "\n",
    "# Get label info\n",
    "labels = trainset.features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "id2label = {str(i): l for i, l in enumerate(labels)}\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "\n",
    "# Preprocessing (ViT processor + optional augmentation)\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(10),\n",
    "    # Do NOT include ToTensor or Normalize here\n",
    "])\n",
    "\n",
    "\n",
    "def transform_examples(batch):\n",
    "    # Data augmentation only on training set\n",
    "    if \"train\" in batch[\"__split__\"][0]:\n",
    "        images = [augment(img.convert(\"RGB\")) for img in batch[\"image\"]]\n",
    "    else:\n",
    "        images = [img.convert(\"RGB\") for img in batch[\"image\"]]\n",
    "    # The processor expects PIL Images or numpy arrays in [0, 255] range\n",
    "    processed = processor(images=images, return_tensors=\"pt\")\n",
    "    # processed[\"pixel_values\"] is a tensor of shape (batch_size, 3, 224, 224)\n",
    "    return {\n",
    "        \"pixel_values\": processed[\"pixel_values\"],\n",
    "        \"labels\": batch[\"label\"]\n",
    "    }\n",
    "# Add split info for augmentation\n",
    "trainset = trainset.add_column(\"__split__\", [\"train\"] * len(trainset))\n",
    "testset = testset.add_column(\"__split__\", [\"test\"] * len(testset))\n",
    "\n",
    "trainset = trainset.map(transform_examples, batched=True, remove_columns=trainset.column_names)\n",
    "testset = testset.map(transform_examples, batched=True, remove_columns=testset.column_names)\n",
    "\n",
    "# Model\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "\n",
    "# Data collator\n",
    "def collate_fn(batch):\n",
    "    # Ensure pixel_values are tensors and stack them\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] if isinstance(x[\"pixel_values\"], torch.Tensor) else torch.tensor(x[\"pixel_values\"]) for x in batch])\n",
    "    labels = torch.tensor([l for x in batch for l in (x[\"labels\"] if isinstance(x[\"labels\"], list) else [x[\"labels\"]])])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "# Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit2-pattern\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,  # Try more epochs for better results\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=8,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=True,\n",
    "    report_to=\"none\",\n",
    "    learning_rate=3e-5,  # Lower learning rate for better fine-tuning\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset,\n",
    "    eval_dataset=testset,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=None,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79e9ba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cef6d5964c4207a5498762f54dc662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:3098: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e04350e6c44eb2a3ac74db93a0ffb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2833: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4204, 'grad_norm': 0.9561194181442261, 'learning_rate': 9.957894736842106e-06, 'epoch': 10.02}\n",
      "{'loss': 0.4244, 'grad_norm': 0.9059658050537109, 'learning_rate': 9.789473684210527e-06, 'epoch': 10.11}\n",
      "{'loss': 0.4234, 'grad_norm': 0.9929202795028687, 'learning_rate': 9.621052631578949e-06, 'epoch': 10.19}\n",
      "{'loss': 0.4175, 'grad_norm': 1.1322929859161377, 'learning_rate': 9.45263157894737e-06, 'epoch': 10.27}\n",
      "{'loss': 0.3923, 'grad_norm': 0.9534863829612732, 'learning_rate': 9.28421052631579e-06, 'epoch': 10.36}\n",
      "{'loss': 0.3972, 'grad_norm': 0.780124306678772, 'learning_rate': 9.11578947368421e-06, 'epoch': 10.44}\n",
      "{'loss': 0.4063, 'grad_norm': 1.0266274213790894, 'learning_rate': 8.947368421052632e-06, 'epoch': 10.53}\n",
      "{'loss': 0.3943, 'grad_norm': 0.9619603753089905, 'learning_rate': 8.778947368421053e-06, 'epoch': 10.61}\n",
      "{'loss': 0.3782, 'grad_norm': 0.8985133767127991, 'learning_rate': 8.610526315789474e-06, 'epoch': 10.69}\n",
      "{'loss': 0.3768, 'grad_norm': 0.8068420886993408, 'learning_rate': 8.442105263157896e-06, 'epoch': 10.78}\n",
      "{'loss': 0.3725, 'grad_norm': 0.8080708980560303, 'learning_rate': 8.273684210526317e-06, 'epoch': 10.86}\n",
      "{'loss': 0.3762, 'grad_norm': 1.1069270372390747, 'learning_rate': 8.105263157894738e-06, 'epoch': 10.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14388134ec044c35b9894c062bf3b78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1161777973175049, 'eval_accuracy': 0.7394736842105263, 'eval_f1': 0.7392406503023499, 'eval_runtime': 53.3603, 'eval_samples_per_second': 7.121, 'eval_steps_per_second': 0.45, 'epoch': 11.0}\n",
      "{'loss': 0.3796, 'grad_norm': 0.7194156646728516, 'learning_rate': 7.93684210526316e-06, 'epoch': 11.03}\n",
      "{'loss': 0.3637, 'grad_norm': 0.8792483806610107, 'learning_rate': 7.768421052631579e-06, 'epoch': 11.12}\n",
      "{'loss': 0.3566, 'grad_norm': 0.7101445198059082, 'learning_rate': 7.600000000000001e-06, 'epoch': 11.2}\n",
      "{'loss': 0.3404, 'grad_norm': 0.6447864174842834, 'learning_rate': 7.431578947368421e-06, 'epoch': 11.28}\n",
      "{'loss': 0.3437, 'grad_norm': 0.7010276317596436, 'learning_rate': 7.2631578947368426e-06, 'epoch': 11.37}\n",
      "{'loss': 0.3457, 'grad_norm': 0.7493733763694763, 'learning_rate': 7.094736842105264e-06, 'epoch': 11.45}\n",
      "{'loss': 0.3481, 'grad_norm': 0.8023068904876709, 'learning_rate': 6.926315789473685e-06, 'epoch': 11.54}\n",
      "{'loss': 0.3363, 'grad_norm': 0.8175363540649414, 'learning_rate': 6.7578947368421054e-06, 'epoch': 11.62}\n",
      "{'loss': 0.3374, 'grad_norm': 0.8551227450370789, 'learning_rate': 6.589473684210527e-06, 'epoch': 11.71}\n",
      "{'loss': 0.3294, 'grad_norm': 0.741298496723175, 'learning_rate': 6.421052631578948e-06, 'epoch': 11.79}\n",
      "{'loss': 0.3364, 'grad_norm': 0.6994035840034485, 'learning_rate': 6.252631578947368e-06, 'epoch': 11.87}\n",
      "{'loss': 0.3219, 'grad_norm': 0.7049347758293152, 'learning_rate': 6.0842105263157895e-06, 'epoch': 11.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1be534441d40a4afe8e162f01ad23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0894335508346558, 'eval_accuracy': 0.7447368421052631, 'eval_f1': 0.7436619178067236, 'eval_runtime': 50.9611, 'eval_samples_per_second': 7.457, 'eval_steps_per_second': 0.471, 'epoch': 12.0}\n",
      "{'loss': 0.3189, 'grad_norm': 0.7114591002464294, 'learning_rate': 5.915789473684211e-06, 'epoch': 12.04}\n",
      "{'loss': 0.323, 'grad_norm': 0.6806594729423523, 'learning_rate': 5.747368421052631e-06, 'epoch': 12.13}\n",
      "{'loss': 0.3123, 'grad_norm': 0.6839451193809509, 'learning_rate': 5.578947368421052e-06, 'epoch': 12.21}\n",
      "{'loss': 0.3115, 'grad_norm': 0.7367866039276123, 'learning_rate': 5.410526315789474e-06, 'epoch': 12.29}\n",
      "{'loss': 0.3008, 'grad_norm': 0.6142610907554626, 'learning_rate': 5.242105263157895e-06, 'epoch': 12.38}\n",
      "{'loss': 0.3128, 'grad_norm': 2.843189001083374, 'learning_rate': 5.073684210526316e-06, 'epoch': 12.46}\n",
      "{'loss': 0.3129, 'grad_norm': 0.6275171637535095, 'learning_rate': 4.9052631578947365e-06, 'epoch': 12.55}\n",
      "{'loss': 0.3125, 'grad_norm': 0.6973397135734558, 'learning_rate': 4.736842105263158e-06, 'epoch': 12.63}\n",
      "{'loss': 0.3042, 'grad_norm': 0.5652658939361572, 'learning_rate': 4.568421052631579e-06, 'epoch': 12.72}\n",
      "{'loss': 0.3051, 'grad_norm': 0.6528241038322449, 'learning_rate': 4.4e-06, 'epoch': 12.8}\n",
      "{'loss': 0.3008, 'grad_norm': 0.6536222100257874, 'learning_rate': 4.2315789473684215e-06, 'epoch': 12.88}\n",
      "{'loss': 0.3004, 'grad_norm': 0.6225923299789429, 'learning_rate': 4.063157894736843e-06, 'epoch': 12.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ea9bd8f86445b988a6e82428cdc8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0814205408096313, 'eval_accuracy': 0.7315789473684211, 'eval_f1': 0.7327807131760055, 'eval_runtime': 53.1242, 'eval_samples_per_second': 7.153, 'eval_steps_per_second': 0.452, 'epoch': 13.0}\n",
      "{'loss': 0.3028, 'grad_norm': 0.6144954562187195, 'learning_rate': 3.894736842105263e-06, 'epoch': 13.05}\n",
      "{'loss': 0.3002, 'grad_norm': 0.6317115426063538, 'learning_rate': 3.7263157894736843e-06, 'epoch': 13.14}\n",
      "{'loss': 0.3018, 'grad_norm': 0.6611103415489197, 'learning_rate': 3.557894736842105e-06, 'epoch': 13.22}\n",
      "{'loss': 0.2925, 'grad_norm': 0.5990911722183228, 'learning_rate': 3.3894736842105264e-06, 'epoch': 13.31}\n",
      "{'loss': 0.2894, 'grad_norm': 0.6253290772438049, 'learning_rate': 3.2210526315789476e-06, 'epoch': 13.39}\n",
      "{'loss': 0.2915, 'grad_norm': 0.5395194888114929, 'learning_rate': 3.0526315789473684e-06, 'epoch': 13.47}\n",
      "{'loss': 0.2871, 'grad_norm': 0.6530255675315857, 'learning_rate': 2.8842105263157897e-06, 'epoch': 13.56}\n",
      "{'loss': 0.2874, 'grad_norm': 0.6690309047698975, 'learning_rate': 2.715789473684211e-06, 'epoch': 13.64}\n",
      "{'loss': 0.2965, 'grad_norm': 0.5859529376029968, 'learning_rate': 2.5473684210526317e-06, 'epoch': 13.73}\n",
      "{'loss': 0.2841, 'grad_norm': 0.6315690875053406, 'learning_rate': 2.378947368421053e-06, 'epoch': 13.81}\n",
      "{'loss': 0.2848, 'grad_norm': 0.5684797763824463, 'learning_rate': 2.2105263157894734e-06, 'epoch': 13.89}\n",
      "{'loss': 0.2754, 'grad_norm': 0.5745885372161865, 'learning_rate': 2.0421052631578946e-06, 'epoch': 13.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9079ecffd2334e14a4eda75f3b199ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.072715401649475, 'eval_accuracy': 0.7368421052631579, 'eval_f1': 0.7375867046891705, 'eval_runtime': 77.58, 'eval_samples_per_second': 4.898, 'eval_steps_per_second': 0.309, 'epoch': 14.0}\n",
      "{'loss': 0.2844, 'grad_norm': 0.6431567668914795, 'learning_rate': 1.8736842105263158e-06, 'epoch': 14.06}\n",
      "{'loss': 0.2756, 'grad_norm': 0.5587624907493591, 'learning_rate': 1.7052631578947369e-06, 'epoch': 14.15}\n",
      "{'loss': 0.2788, 'grad_norm': 0.5767632126808167, 'learning_rate': 1.5368421052631579e-06, 'epoch': 14.23}\n",
      "{'loss': 0.2837, 'grad_norm': 0.7035180330276489, 'learning_rate': 1.3684210526315791e-06, 'epoch': 14.32}\n",
      "{'loss': 0.2839, 'grad_norm': 0.6471250653266907, 'learning_rate': 1.2000000000000002e-06, 'epoch': 14.4}\n",
      "{'loss': 0.2806, 'grad_norm': 0.7250261902809143, 'learning_rate': 1.031578947368421e-06, 'epoch': 14.48}\n",
      "{'loss': 0.2801, 'grad_norm': 0.6492757797241211, 'learning_rate': 8.631578947368421e-07, 'epoch': 14.57}\n",
      "{'loss': 0.2747, 'grad_norm': 0.7524358034133911, 'learning_rate': 6.947368421052632e-07, 'epoch': 14.65}\n",
      "{'loss': 0.2884, 'grad_norm': 0.592825710773468, 'learning_rate': 5.263157894736842e-07, 'epoch': 14.74}\n",
      "{'loss': 0.2876, 'grad_norm': 0.6566399335861206, 'learning_rate': 3.578947368421053e-07, 'epoch': 14.82}\n",
      "{'loss': 0.2819, 'grad_norm': 0.6125015020370483, 'learning_rate': 1.8947368421052632e-07, 'epoch': 14.91}\n",
      "{'loss': 0.2762, 'grad_norm': 0.5745024681091309, 'learning_rate': 2.1052631578947368e-08, 'epoch': 14.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e2ef0617ec49529ee5a4b4d8e2c0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0711021423339844, 'eval_accuracy': 0.7368421052631579, 'eval_f1': 0.7375867046891705, 'eval_runtime': 131.5153, 'eval_samples_per_second': 2.889, 'eval_steps_per_second': 0.182, 'epoch': 15.0}\n",
      "{'train_runtime': 2194.7286, 'train_samples_per_second': 10.389, 'train_steps_per_second': 0.649, 'train_loss': 0.10791874935752467, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf35163e3a254ba5920f5ebcd36994b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0711021423339844, 'eval_accuracy': 0.7368421052631579, 'eval_f1': 0.7375867046891705, 'eval_runtime': 91.4089, 'eval_samples_per_second': 4.157, 'eval_steps_per_second': 0.263, 'epoch': 15.0}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load dataset and split\n",
    "dataset = load_dataset(\"yainage90/fashion-pattern-images\")\n",
    "split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "trainset = split[\"train\"]\n",
    "testset = split[\"test\"]\n",
    "\n",
    "# Get label info\n",
    "labels = trainset.features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "id2label = {str(i): l for i, l in enumerate(labels)}\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "\n",
    "# Preprocessing (ViT processor + optional augmentation)\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(10),\n",
    "    # Do NOT include ToTensor or Normalize here\n",
    "])\n",
    "\n",
    "\n",
    "def transform_examples(batch):\n",
    "    # Data augmentation only on training set\n",
    "    if \"train\" in batch[\"__split__\"][0]:\n",
    "        images = [augment(img.convert(\"RGB\")) for img in batch[\"image\"]]\n",
    "    else:\n",
    "        images = [img.convert(\"RGB\") for img in batch[\"image\"]]\n",
    "    # The processor expects PIL Images or numpy arrays in [0, 255] range\n",
    "    processed = processor(images=images, return_tensors=\"pt\")\n",
    "    # processed[\"pixel_values\"] is a tensor of shape (batch_size, 3, 224, 224)\n",
    "    return {\n",
    "        \"pixel_values\": processed[\"pixel_values\"],\n",
    "        \"labels\": batch[\"label\"]\n",
    "    }\n",
    "# Add split info for augmentation\n",
    "trainset = trainset.add_column(\"__split__\", [\"train\"] * len(trainset))\n",
    "testset = testset.add_column(\"__split__\", [\"test\"] * len(testset))\n",
    "\n",
    "trainset = trainset.map(transform_examples, batched=True, remove_columns=trainset.column_names)\n",
    "testset = testset.map(transform_examples, batched=True, remove_columns=testset.column_names)\n",
    "\n",
    "# Model\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "\n",
    "# Data collator\n",
    "def collate_fn(batch):\n",
    "    # Ensure pixel_values are tensors and stack them\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] if isinstance(x[\"pixel_values\"], torch.Tensor) else torch.tensor(x[\"pixel_values\"]) for x in batch])\n",
    "    labels = torch.tensor([l for x in batch for l in (x[\"labels\"] if isinstance(x[\"labels\"], list) else [x[\"labels\"]])])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "# Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit2-pattern\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,  # Try more epochs for better results\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=8,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=True,\n",
    "    report_to=\"none\",\n",
    "    learning_rate=3e-5,  # Lower learning rate for better fine-tuning\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset,\n",
    "    eval_dataset=testset,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=None,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train(resume_from_checkpoint=\"./vit2-pattern/checkpoint-950\")\n",
    "\n",
    "# Evaluate\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "830b3e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./vit2-pattern-final\\\\preprocessor_config.json']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"./vit2-pattern-final\")\n",
    "# Save the processor\n",
    "processor.save_pretrained(\"./vit2-pattern-final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
